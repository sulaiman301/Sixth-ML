import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report

def load_data(file_path):
    df = pd.read_excel(file_path)
    return df

def preprocess_data(df):
    # Handle missing values
    df["Churn Reason"] = df["Churn Reason"].fillna(df["Churn Reason"].mode()[0])
    
    # Drop irrelevant columns
    df = df.drop(columns=['CustomerID', 'Count', 'Country', 'State', 'City', 'Zip Code', 'Lat Long', 'Churn Reason'])
    
    # Convert 'Total Charges' to numeric
    df['Total Charges'] = pd.to_numeric(df['Total Charges'], errors='coerce').fillna(0)
    
    # One-hot encode categorical variables
    categorical_columns = ['Gender', 'Senior Citizen', 'Partner', 'Dependents', 
                           'Phone Service', 'Multiple Lines', 'Internet Service', 
                           'Online Security', 'Online Backup', 'Device Protection', 
                           'Tech Support', 'Streaming TV', 'Streaming Movies', 
                           'Contract', 'Paperless Billing', 'Payment Method']
    
    df_encoded = pd.get_dummies(df, columns=categorical_columns, drop_first=True)
    
    # Convert 'Churn Label' to binary
    df_encoded['Churn Label'] = df_encoded['Churn Label'].apply(lambda x: 1 if x == 'Yes' else 0)
    
    return df_encoded

def split_data(df_encoded):
    X = df_encoded.drop('Churn Label', axis=1)
    y = df_encoded['Churn Label']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    return X_train, X_test, y_train, y_test

def scale_features(X_train, X_test):
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    return X_train, X_test

def plot_univariate(df, numerical_features, categorical_features):
    for feature in numerical_features:
        plt.figure(figsize=(10, 4))
        sns.histplot(df[feature], kde=True)
        plt.title(f'Distribution of {feature}')
        plt.xlabel(feature)
        plt.ylabel('Frequency')
        plt.show()
    
    for feature in categorical_features:
        plt.figure(figsize=(10, 4))
        sns.countplot(x=feature, data=df)
        plt.title(f'Count of {feature}')
        plt.xlabel(feature)
        plt.ylabel('Count')
        plt.show()

def plot_bivariate(df, numerical_features, categorical_features, target_variable):
    for feature in numerical_features:
        plt.figure(figsize=(10, 4))
        sns.boxplot(x=target_variable, y=feature, data=df)
        plt.title(f'{feature} vs {target_variable}')
        plt.xlabel(target_variable)
        plt.ylabel(feature)
        plt.show()
    
    for feature in categorical_features:
        if feature != target_variable:
            plt.figure(figsize=(10, 4))
            sns.countplot(x=feature, hue=target_variable, data=df)
            plt.title(f'{feature} vs {target_variable}')
            plt.xlabel(feature)
            plt.ylabel('Count')
            plt.show()

def train_models(X_train, y_train):
    models = {
        "Logistic Regression": LogisticRegression(),
        "Random Forest": RandomForestClassifier(),
        "Support Vector Classifier": SVC(),
        "K-Nearest Neighbors": KNeighborsClassifier()
    }
    
    for name, model in models.items():
        model.fit(X_train, y_train)
        print(f"{name} trained successfully.")
    
    return models

def evaluate_model(model, X_test, y_test):
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    return accuracy, precision, recall, f1

def evaluate_models(models, X_test, y_test):
    for name, model in models.items():
        accuracy, precision, recall, f1 = evaluate_model(model, X_test, y_test)
        print(f"{name} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}")

def plot_confusion_matrix(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix for {model_name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.show()

def plot_confusion_matrices(models, X_test, y_test):
    for name, model in models.items():
        plot_confusion_matrix(model, X_test, y_test, name)

def cross_validate_model(model, X, y):
    scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
    return scores.mean(), scores.std()

def cross_validate_models(models, X, y):
    for name, model in models.items():
        mean_score, std_dev = cross_validate_model(model, X, y)
        print(f"{name} - Cross-Validation Accuracy: {mean_score:.4f} Â± {std_dev:.4f}")

def print_classification_reports(models, X_test, y_test):
    for name, model in models.items():
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        
        print(f"\n{name} Model Evaluation:")
        print(f"Accuracy: {accuracy:.4f}")
        print(f"Precision: {precision:.4f}")
        print(f"Recall: {recall:.4f}")
        print(f"F1 Score: {f1:.4f}")
        print("Confusion Matrix:")
        print(confusion_matrix(y_test, y_pred))
        print("Classification Report:")
        print(classification_report(y_test, y_pred))
